{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2701f0c8-15ce-4135-a02a-4946d0730d33",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import requests\n",
    "import gzip\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import io\n",
    "import numpy.core.multiarray as multi\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf\n",
    "import gzip\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio as iAudio\n",
    "from npc_gzip.compressors.bz2_compressor import Bz2Compressor\n",
    "from npc_gzip.compressors.gzip_compressor import GZipCompressor\n",
    "from npc_gzip.knn_classifier import KnnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a3f9b1-abf7-4c42-bf6a-ac1aaa421eb1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(dataset) -> tuple:\n",
    "    \"\"\"\n",
    "    Pulls the Project CETI sperm whale vocalizations\n",
    "    training data and the second being the test\n",
    "    data. Each tuple contains the audio and label\n",
    "    respectively as numpy arrays.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    train_iter = dataset['train']\n",
    "    test_iter = dataset['test']\n",
    "\n",
    "    train_audio =  [audio_array['bytes'] for audio_array in train_iter['audio']]\n",
    "    train_labels = train_iter['coda_type']\n",
    "    \n",
    "    test_audio  = [audio_array['bytes'] for audio_array in test_iter['audio']]\n",
    "    test_labels = test_iter['coda_type']\n",
    "    \n",
    "    train_audio = np.array(train_audio)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    test_audio = np.array(test_audio)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    train = (train_audio, train_labels)\n",
    "    test = (test_audio, test_labels)\n",
    "\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d292a7-eab3-4ca4-994d-db6de76d2268",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_model(train_audio: np.ndarray, train_labels: np.ndarray, distance_metric: str = \"ncd\") -> KnnClassifier:\n",
    "    \"\"\"\n",
    "    Fits a Knn-GZip compressor on the train\n",
    "    data and returns it.\n",
    "\n",
    "    Arguments:\n",
    "        train_text (np.ndarray): Training dataset as a numpy array.\n",
    "        train_labels (np.ndarray): Training labels as a numpy array.\n",
    "\n",
    "    Returns:\n",
    "        KnnClassifier: Trained Knn-Compressor model ready to make predictions.\n",
    "    \"\"\"\n",
    "    compressor: BaseCompressor = Bz2Compressor()\n",
    "    model: KnnClassifier = KnnClassifier(\n",
    "        compressor=compressor,\n",
    "        training_inputs=train_audio,\n",
    "        training_labels=train_labels,\n",
    "        distance_metric=distance_metric,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605b895e-ffe1-4b63-aceb-6752ea5adabe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"autumnjohnson/ceti_audio\").cast_column(\"audio\", Audio(decode=False, sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec38ebc0-04f2-4738-8382-a8b11bb9837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "((train_audio, train_labels), (test_audio, test_labels)) = get_data(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c44dab-06b9-4b4e-8cfd-c22986ea4de8",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b8b5d2-0557-4e5a-9944-ad515810dd6d",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = fit_model(train_audio, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44c40f-39a6-4196-8b94-b635f9d4d347",
   "metadata": {},
   "source": [
    "## Initialize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217dd5fa-2290-49b4-b8bb-b44a578524e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_indicies = np.random.choice(test_audio.shape[0], len(test_audio), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "854af5c7-92fe-4491-a223-48443be667ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_test_text = test_audio[random_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c1be452-63ff-495e-b359-4923bef47efd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_test_labels = test_labels[random_indicies]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2690a15-6e32-40a2-83b3-8843256f98af",
   "metadata": {},
   "source": [
    "## Generate predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18755c1-d5b5-443e-87ae-04016f06d56f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing input...:  21%|██        | 75/353 [00:24<01:37,  2.86it/s]"
     ]
    }
   ],
   "source": [
    " # Here we use the `sampling_percentage` to save time\n",
    " # at the expense of worse predictions. This\n",
    " # `sampling_percentage` selects a random % of training\n",
    " # data to compare `sample_test_text` against rather\n",
    " # than comparing it against the entire training dataset.\n",
    "top_k = 1\n",
    "(distances, labels, similar_samples) = model.predict(sample_test_text, top_k, sampling_percentage=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7e3b7c-edf3-4f86-a35b-62110b7d673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_labels = labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ced27-d60c-4b94-8e61-8c9d83578e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Counter(flattened_labels)  \n",
    "l = Counter(sample_test_labels)\n",
    "x =(l['1+1+3']+p['1+1+3'])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037a248-2e87-4c50-bdd8-cd58c66e491e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(sample_test_labels, flattened_labels.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671995ba-da3d-43bc-80cb-a00242440fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(sample_test_labels, flattened_labels.reshape(-1))\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a13372-b67b-4f88-ab30-aae2dc482d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(sample_test_labels, flattened_labels.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b503d4-9f28-4831-8042-25ec2fd6ed31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1434390-a26d-477d-909a-d53fa19dda5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83187a21-b401-46b0-9377-ed4a0fcd130b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
