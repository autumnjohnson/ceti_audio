{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2701f0c8-15ce-4135-a02a-4946d0730d33",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "import random\n",
    "import requests\n",
    "import gzip\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import io\n",
    "import numpy.core.multiarray as multi\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf\n",
    "import gzip\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio as iAudio\n",
    "from npc_gzip.compressors.gzip_compressor import GZipCompressor\n",
    "from npc_gzip.knn_classifier import KnnClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d8e6eea-05ec-450e-8013-70298695ccb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reference:\n",
    "# Input: The Audio feature accepts as input:\n",
    "#     A str: Absolute path to the audio file (i.e. random access is allowed).\n",
    "#     A dict with the keys:\n",
    "#         path: String with relative path of the audio file to the archive file.\n",
    "#         bytes: Bytes content of the audio file.\n",
    "\n",
    "# Convert the NumPy arrays to audio bytes in WAV format\n",
    "def numpy_to_bytes(audio_array, sampling_rate=16000):\n",
    "    with io.BytesIO() as bytes_io:\n",
    "        sf.write(bytes_io, audio_array, samplerate=sampling_rate, format='WAV')\n",
    "        return bytes_io.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47a3f9b1-abf7-4c42-bf6a-ac1aaa421eb1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(dataset) -> tuple:\n",
    "    \"\"\"\n",
    "    Pulls the Project CETI sperm whale vocalizations\n",
    "    training data and the second being the test\n",
    "    data. Each tuple contains the audio and label\n",
    "    respectively as numpy arrays.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    train_iter = dataset['train']\n",
    "    test_iter = dataset['test']\n",
    "\n",
    "    train_audio =  [numpy_to_bytes(audio_array['array']) for audio_array in train_iter['audio']]\n",
    "    train_labels = train_iter['coda_type']\n",
    "    \n",
    "    test_audio  = [numpy_to_bytes(audio_array['array']) for audio_array in test_iter['audio']]\n",
    "    test_labels = test_iter['coda_type']\n",
    "    \n",
    "    train_audio = np.array(train_audio)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    test_audio = np.array(test_audio)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    train = (train_audio, train_labels)\n",
    "    test = (test_audio, test_labels)\n",
    "\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2d292a7-eab3-4ca4-994d-db6de76d2268",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_model(train_audio: np.ndarray, train_labels: np.ndarray, distance_metric: str = \"ncd\") -> KnnClassifier:\n",
    "    \"\"\"\n",
    "    Fits a Knn-GZip compressor on the train\n",
    "    data and returns it.\n",
    "\n",
    "    Arguments:\n",
    "        train_text (np.ndarray): Training dataset as a numpy array.\n",
    "        train_labels (np.ndarray): Training labels as a numpy array.\n",
    "\n",
    "    Returns:\n",
    "        KnnClassifier: Trained Knn-Compressor model ready to make predictions.\n",
    "    \"\"\"\n",
    "    compressor: BaseCompressor = GZipCompressor()\n",
    "    model: KnnClassifier = KnnClassifier(\n",
    "        compressor=compressor,\n",
    "        training_inputs=train_audio,\n",
    "        training_labels=train_labels,\n",
    "        distance_metric=distance_metric,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "605b895e-ffe1-4b63-aceb-6752ea5adabe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"autumnjohnson/ceti_audio\")#.cast_column(\"audio\", Audio(decode=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96d0314e-66d0-49f9-aacb-2397286d39b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "((train_audio, train_labels), (test_audio, test_labels)) = get_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b8b5d2-0557-4e5a-9944-ad515810dd6d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = fit_model(train_audio, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217dd5fa-2290-49b4-b8bb-b44a578524e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_indicies = np.random.choice(test_audio.shape[0], len(test_audio), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854af5c7-92fe-4491-a223-48443be667ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_test_text = test_audio[random_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1be452-63ff-495e-b359-4923bef47efd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_test_labels = test_labels[random_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18755c1-d5b5-443e-87ae-04016f06d56f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Here we use the `sampling_percentage` to save time\n",
    " # at the expense of worse predictions. This\n",
    " # `sampling_percentage` selects a random % of training\n",
    " # data to compare `sample_test_text` against rather\n",
    " # than comparing it against the entire training dataset.\n",
    "top_k = 1\n",
    "(distances, labels, similar_samples) = model.predict(sample_test_text, top_k, sampling_percentage=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7e3b7c-edf3-4f86-a35b-62110b7d673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_labels = labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ced27-d60c-4b94-8e61-8c9d83578e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Counter(flattened_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bcb28b-4af8-4e1d-a7d9-bb6bfd4e7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Counter(sample_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e80deb-952a-4910-90dd-da6e8400462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =(l['1+1+3']+p['1+1+3'])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037a248-2e87-4c50-bdd8-cd58c66e491e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(sample_test_labels, flattened_labels.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564981f1-2153-4dee-a5cb-98ad996b3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train']['audio'][0]['array'].decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6dca2d-0ca6-442a-9466-353ed9032d44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xfunc(c):\n",
    "    bincount = np.bincount(c)\n",
    "    argmax = np.argmax(bincount, axis=0)\n",
    "    \n",
    "    return argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671995ba-da3d-43bc-80cb-a00242440fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(sample_test_labels, flattened_labels.reshape(-1))\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a13372-b67b-4f88-ab30-aae2dc482d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(sample_test_labels, flattened_labels.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937ec96-c813-4c1d-b7a3-f1a04349ba62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706cd551-6d40-4b23-a370-64711cbac435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125bf193-c6b4-447d-b34f-3b36910b5582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01219b-371f-4fe3-9a9c-0be58d15b981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
